{
  "hash": "98082a0a5aef82eb411ce077dc50a6d9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Intro\n---\n\nBasically, Bayesian statistics involves taking some prior beliefs and combining them with data to produce an updated (posterior) set of beliefs. In statistics-world, these beliefs are encoded as distributions (or combinations of distributions).\n\n## Probability\n\nBayesian and frequentist frameworks tend to differ on what \"probability\" means. In a Bayesian framework, probability refers to the plausibility of an event. And this tends to be how most people use the term \"probability\" in informal settings. If we say that the Chiefs have a 90% probability of winning a game vs the Broncos, we're probably using \"probability\" in the Bayesian sense.\n\nFrequentists, on the other hand, use probability to mean the relative frequency of a given event if it were repeated a lot of times. So in the above example, if this exact Chiefs team played this exact Broncos team in the same conditions 1,000 times, we'd expect them to win 900 of those games.\n\n## Testing Hypotheses\n\nIn a Bayesian framework, we ask this question: In light of the observed data, what’s the chance that the hypothesis is correct?\n\nIn a frequentist framework, we ask this question: If in fact the hypothesis is incorrect, what’s the chance I’d have observed this, or even more extreme, data?\n\n(note that both of the above are from [Ch 1 of Bayes Rules!](https://www.bayesrulesbook.com/chapter-1#thinking-like-a-bayesian))\n\n## Some Terminology\n\n*Unconditional probability*: $P(Y)$ -- the probability of X (e.g. the probability that an email is spam)\n\n*Conditional probability*: $P(Y|X)$ -- the probability of Y given X (e.g. the probability that an email is spam given that there's an exclamation mark in the subject line).\n\nIn some cases, $P(Y|X) > P(Y)$, for example $P(orchestra | practice) > P(orchestra)$, but in other cases, $P(Y|X) < P(Y)$, for example $P(flu | wash hands) < P(flu)$\n\nOrdering is also important. Typically $P(Y|X) \\neq P(X|Y)$.\n\n*Independence*: two events are independent if $P(Y|X) = P(Y)$.\n\n*Joint probability*: $P(Y \\cap X)$ probabilty of Y **and** X. Assuming X is a binary variable, the total probability of observing Y is: $P(Y) = P(Y \\cap X) + P(Y \\cap X^c)$, where $X^c$ refers to \"not X\"\n\n### Probability vs Likelihood\n\nWhen B is known, the conditional probability function $P(\\cdot|B)$ allows us to compare the probabilities of an unknown event, A or $A^c$, ocurring with B:\n\n$P(A|B)$ vs $P(A^c|B)$\n\nWhen A is known, the likelihood function $L(\\cdot|A) = P(A|\\cdot)$ allows us to evaluate the relative compatibility of data A with events B or $B^c$:\n\n$L(B|A)$ vs $L(B^c|A)$.\n\nFor example, when Y = y is known, we can use a likelihood function ($L(\\cdot |y) = f(y|\\cdot)$) to compare the relative likelihood of observing data *y* under possible values of $\\pi$ (in a binomial distribution), e.g. ($L(\\pi_1 | y)$ vs $L(\\pi_2 | y)$).\n\n### Calculating Joint probability\n\n$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$\n\n## Bayes' Rule\n\nFor events A and B, the posterior probability of B given A is:\n\n$P(B|A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{P(B)L(B|A)}{P(A)}$\n\nwhere\n\n$P(A) = P(B)L(B|A) + P(B^c)L(B^c|A)$\n\nor more generally:\n\n$posterior = \\frac{prior \\cdot likelihood}{normalizing constant}$\n\nAnother way to think about this:\n\n$f(\\pi | y) = \\frac{f(\\pi)L(\\pi|y)}{f(y)}$\n\n\n## Worked example\n\n::: {#95dcc2f3 .cell execution_count=1}\n``` {.julia .cell-code}\nusing RDatasets\nusing DataFrames\nusing Statistics\nusing Chain\n\ndefault = dataset(\"ISLR\", \"Default\")\n\n#we'll just use default and student for this\nd = default[:, [:Default, :Student]]\nd.:Default .= d.:Default .== \"Yes\"\nd.:Student .= d.:Student .== \"Yes\"\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n10000-element BitVector:\n 0\n 1\n 0\n 0\n 0\n 1\n 0\n 1\n 0\n 0\n 1\n 1\n 0\n ⋮\n 0\n 1\n 0\n 0\n 0\n 0\n 1\n 0\n 0\n 0\n 0\n 1\n```\n:::\n:::\n\n\nlet's look at the overall probability of default\n\n::: {#777c1b7c .cell execution_count=2}\n``` {.julia .cell-code}\nmean(d.:Default)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n0.0333\n```\n:::\n:::\n\n\nand the overall probability of being a student\n\n::: {#27c739fa .cell execution_count=3}\n``` {.julia .cell-code}\nmean(d.:Student)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n0.2944\n```\n:::\n:::\n\n\nand the probability of default by student type\n\n::: {#3c4167fc .cell execution_count=4}\n``` {.julia .cell-code}\np_tbl = @chain d begin\n    groupby(:Student)\n    combine(:Default => mean)\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div><div style = \"float: left;\"><span>2×2 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Student</th><th style = \"text-align: left;\">Default_mean</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Bool\" style = \"text-align: left;\">Bool</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">0.029195</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">0.0431386</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nso, the likelihoods for student types are, $L(S|D) = .043$ and $L(S^c|D) = .029$\n\nIf we want to figure out the probability of default for students, we can use:\n\n$P(S|D) = \\frac{P(S)L(S|D)}{P(D)}$\n\n::: {#9aa200a2 .cell execution_count=5}\n``` {.julia .cell-code}\np_s_d = (mean(d.:Student) * 0.043) / (mean(d.:Default))\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n0.3801561561561561\n```\n:::\n:::\n\n\nSo, given this, if we know someone defaults, there's a 38% probability that they're a student\n\n",
    "supporting": [
      "ch1_intro_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}