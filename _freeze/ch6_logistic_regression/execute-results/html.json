{
  "hash": "6f0b66f458a7ab01aed57e646c23f3b1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Ch 6 - Bayesian Logistic Regression\"\njuptyer: julia-1.9\n---\n\nIn this chapter, I'm going to walk through fitting a bayesian logistic regression. This is analogous to the previous chapter where I fit a linear regression, but, uh, it's a logistic regression.\n\nJust like in the last chapter, I'm going to use Julia's [Turing.jl](https://turinglang.org) package. This example is drawn (heavily) from [Jose Storopoli's bayesian stats notes](https://storopoli.io/Bayesian-Julia/pages/07_logistic_reg/).\n\nFirst, I'll load some libraries and read in some data.\n\n::: {#d765882c .cell execution_count=1}\n``` {.julia .cell-code}\nusing Distributions\nusing Plots\nusing Turing\nusing Random\nusing DataFrames\nusing LazyArrays\nusing CSV\n\nRandom.seed!(0408)\n\n#read in data\nurl = \"https://raw.githubusercontent.com/storopoli/Bayesian-Julia/master/datasets/wells.csv\"\n\nwells = CSV.read(download(url), DataFrame)\n\ndescribe(wells)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div><div style = \"float: left;\"><span>5×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">variable</th><th style = \"text-align: left;\">mean</th><th style = \"text-align: left;\">min</th><th style = \"text-align: left;\">median</th><th style = \"text-align: left;\">max</th><th style = \"text-align: left;\">nmissing</th><th style = \"text-align: left;\">eltype</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Symbol\" style = \"text-align: left;\">Symbol</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Real\" style = \"text-align: left;\">Real</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Real\" style = \"text-align: left;\">Real</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"DataType\" style = \"text-align: left;\">DataType</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">switch</td><td style = \"text-align: right;\">0.575166</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">arsenic</td><td style = \"text-align: right;\">1.65693</td><td style = \"text-align: right;\">0.51</td><td style = \"text-align: right;\">1.3</td><td style = \"text-align: right;\">9.65</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">dist</td><td style = \"text-align: right;\">48.3319</td><td style = \"text-align: right;\">0.387</td><td style = \"text-align: right;\">36.7615</td><td style = \"text-align: right;\">339.531</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">assoc</td><td style = \"text-align: right;\">0.422848</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">educ</td><td style = \"text-align: right;\">4.82848</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">17</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThe outcome variable in this dataset is `switch` -- a binary indicator of whether a household switched wells after being informed that the wells they'd been using previously were contaminated.\n\nSo a first step then is to separate the outcome from the rest of the predictors.\n\n*Note -- it's best practice to explore the data and do some feature engineering (e.g. z-scoring numeric predictors). But I'm not going to do that here because I don't really care about the quality of the model in this contrived example.*\n\n::: {#c4e2cd78 .cell execution_count=2}\n``` {.julia .cell-code}\nX = Matrix(select(wells, Not(:switch)))\ny = wells.:switch\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n3020-element Vector{Int64}:\n 1\n 1\n 0\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n ⋮\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 1\n```\n:::\n:::\n\n\nHere's what we're modeling:\n\n$P(switch_i) = Logistic(\\alpha +\\beta^T \\bf X_i)$\n\nIn words -- that the probability of switching wells is equal to the logistic transformation of a linear combination of $\\alpha + \\beta^T \\bf X_i$, which is just the linear regression model. \n\nAnd recall that the logistic function is:\n\n$Logistic(x) = \\frac{1}{1 + e^{(-x)}}$\n\n## Define the model\n\nJust as we did in the linear regression model, we define a logistic regression using Turin's `@model macro`. Once again, this uses pretty weak priors, and each variable gets the same prior here\n\n::: {#fd3def4f .cell execution_count=3}\n``` {.julia .cell-code}\n@model function log_reg(X, y)\n    n_feat = size(X, 2)\n\n    #priors\n    α ~ Normal(0, 3)\n    β ~ filldist(TDist(3), n_feat)\n\n    #likelihood\n    return y ~ arraydist(LazyArray(@~ BernoulliLogit.(α .+ X * β)))\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nlog_reg (generic function with 2 methods)\n```\n:::\n:::\n\n\nIn notation:\n\n$y \\sim Bernoulli(p)$\n\n$p \\sim Logistic(\\alpha + \\bf X \\cdot \\beta)$\n\n$\\alpha \\sim N(0, 3)$\n\n$\\beta_j \\sim t(0, 1, 3)$ for j in $\\{\\beta_1, ..., \\beta_j\\}$\n\nAlso -- the model specification above comes from Jose Storopoli's code, and there are a few little wrinkles I didn't quite understand at first:\n\n- `filldist()`is basically a loop to make the same distribution multiple times. So for example, it will create `n_feat` identical distributions (T distributions with 3 degrees of freedom);\n- `arraydist()` is similar to `filldist()`, but it is a wrapper for an array of distributions that aren't necessarily the same.\n- As far as I can tell, `LazyArray()` and `@~` provide ways to specify lazy computations, which make the operations faster and more efficient.\n- `BernoulliLogit()` is a cool way to combine the `Logistic()` and `Bernoulli()` functions.\n\n## Simulate the Posterior\n\nThen we can simulate the posterior just like we did before:\n\n::: {#a3f9dc88 .cell execution_count=4}\n``` {.julia .cell-code}\nm = log_reg(X, y)\n\nchn = sample(m, NUTS(), MCMCThreads(), 1_000, 3);\n\nsummarize(chn)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n┌ Warning: Only a single thread available: MCMC chains are not sampled in parallel\n└ @ AbstractMCMC C:\\Users\\eric_ekholm\\.julia\\packages\\AbstractMCMC\\Es490\\src\\sample.jl:307\n┌ Info: Found initial step size\n└   ϵ = 0.003125\n┌ Info: Found initial step size\n└   ϵ = 0.003125\n┌ Info: Found initial step size\n└   ϵ = 0.0125\n\rSampling (1 threads):  67%|████████████████████         |  ETA: 0:00:02\rSampling (1 threads): 100%|█████████████████████████████| Time: 0:00:08\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=5}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre> <span class=\"ansi-bold\"> parameters </span> <span class=\"ansi-bold\">    mean </span> <span class=\"ansi-bold\">     std </span> <span class=\"ansi-bold\">    mcse </span> <span class=\"ansi-bold\">  ess_bulk </span> <span class=\"ansi-bold\">  ess_tail </span> <span class=\"ansi-bold\">    rhat </span>  ⋯\n <span class=\"ansi-bright-black-fg\">     Symbol </span> <span class=\"ansi-bright-black-fg\"> Float64 </span> <span class=\"ansi-bright-black-fg\"> Float64 </span> <span class=\"ansi-bright-black-fg\"> Float64 </span> <span class=\"ansi-bright-black-fg\">   Float64 </span> <span class=\"ansi-bright-black-fg\">   Float64 </span> <span class=\"ansi-bright-black-fg\"> Float64 </span>  ⋯\n           α   -0.1551    0.0994    0.0028   1256.7607   1606.9207    1.0026   ⋯\n        β[1]    0.4671    0.0408    0.0011   1371.1125   1734.0509    1.0030   ⋯\n        β[2]   -0.0090    0.0011    0.0000   3094.1331   2249.2855    1.0008   ⋯\n        β[3]   -0.1230    0.0750    0.0018   1673.0766   1576.0275    1.0006   ⋯\n        β[4]    0.0423    0.0096    0.0002   1800.2146   1864.5301    1.0015   ⋯\n<span class=\"ansi-cyan-fg\">                                                                1 column omitted</span>\n</pre>\n```\n:::\n\n:::\n:::\n\n\n## Trying another Version\n\nOk, so just to prove that the `arraydist(...)` term is doing what I think it's doing in the model above, I'm going to define a second model that's hopefully equivalent to the first! \n\n::: {#9ab7f691 .cell execution_count=5}\n``` {.julia .cell-code}\n@model function log_reg2(X, y)\n    n_feat = size(X, 2)\n\n    #priors\n    α ~ Normal(0, 3)\n    β ~ filldist(TDist(3), n_feat)\n\n    for i ∈ eachindex(y)\n        y[i] ~ BernoulliLogit(α + X[i, :]' * β)\n    end\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nlog_reg2 (generic function with 2 methods)\n```\n:::\n:::\n\n\n::: {#e6990362 .cell execution_count=6}\n``` {.julia .cell-code}\nm2 = log_reg2(X, y)\n\nchn2 = sample(m2, NUTS(), MCMCThreads(), 1_000, 3);\n\nsummarize(chn2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n┌ Warning: Only a single thread available: MCMC chains are not sampled in parallel\n└ @ AbstractMCMC C:\\Users\\eric_ekholm\\.julia\\packages\\AbstractMCMC\\Es490\\src\\sample.jl:307\n┌ Info: Found initial step size\n└   ϵ = 0.0015625\n┌ Info: Found initial step size\n└   ϵ = 0.00625\n┌ Info: Found initial step size\n└   ϵ = 0.00625\n\rSampling (1 threads):  67%|████████████████████         |  ETA: 0:00:04\rSampling (1 threads): 100%|█████████████████████████████| Time: 0:00:18\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre> <span class=\"ansi-bold\"> parameters </span> <span class=\"ansi-bold\">    mean </span> <span class=\"ansi-bold\">     std </span> <span class=\"ansi-bold\">    mcse </span> <span class=\"ansi-bold\">  ess_bulk </span> <span class=\"ansi-bold\">  ess_tail </span> <span class=\"ansi-bold\">    rhat </span>  ⋯\n <span class=\"ansi-bright-black-fg\">     Symbol </span> <span class=\"ansi-bright-black-fg\"> Float64 </span> <span class=\"ansi-bright-black-fg\"> Float64 </span> <span class=\"ansi-bright-black-fg\"> Float64 </span> <span class=\"ansi-bright-black-fg\">   Float64 </span> <span class=\"ansi-bright-black-fg\">   Float64 </span> <span class=\"ansi-bright-black-fg\"> Float64 </span>  ⋯\n           α   -0.1574    0.0988    0.0028   1292.1404   1714.7255    1.0039   ⋯\n        β[1]    0.4661    0.0414    0.0011   1505.7384   1585.0674    1.0012   ⋯\n        β[2]   -0.0090    0.0010    0.0000   3255.5574   2392.8436    1.0014   ⋯\n        β[3]   -0.1216    0.0772    0.0019   1568.5344   1852.0284    1.0008   ⋯\n        β[4]    0.0427    0.0100    0.0002   1702.9298   1573.2741    1.0022   ⋯\n<span class=\"ansi-cyan-fg\">                                                                1 column omitted</span>\n</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#f47b7ef3 .cell execution_count=7}\n``` {.julia .cell-code}\nisapprox(summarize(chn2)[:, :mean], summarize(chn)[:, :mean], atol=0.01)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\ntrue\n```\n:::\n:::\n\n\n## Extracting, Predicting, Etc\n\nThe process for extracting information from the chains, predicting Y, etc. is going to be the same as it was for linear regression (since it uses the same API), so I'm not going to go through all of that here and instead just refer myself back to the [linear_regression](ch5_linear_regression.qmd) page.\n\n",
    "supporting": [
      "ch6_logistic_regression_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}